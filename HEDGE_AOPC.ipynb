{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Hierarchical Explanation via Divisive Generation (HEDGE) AOPC Calculation for BERT Sequence Classification Models\n",
        "==================================================================\n",
        "This script demonstrates how to compute HEDGE attributions and AOPC (Area Over the Perturbation Curve)\n",
        "for a HuggingFace Transformer model. HEDGE helps explain predictions by identifying which parts of text\n",
        "are most important for a model's decision.\n",
        "The script is designed to be run locally or on a hosted runtime like Colab.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "-------------\n",
        "1. Install requirements (see below).\n",
        "2. Set your own HuggingFace model and tokenizer, and provide paths to your train/test data.\n",
        "3. Run the script!\n",
        "\n",
        "REQUIREMENTS:\n",
        "-------------\n",
        "!pip install transformers datasets lime pandas torch\n",
        "\n",
        "If running in Colab, uncomment and run the pip commands at the top of your notebook.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import itertools\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "from copy import copy, deepcopy\n",
        "from itertools import combinations\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import TextClassificationPipeline"
      ],
      "metadata": {
        "id": "4fNbuIyTnD5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: Login to your HuggingFace Hub account"
      ],
      "metadata": {
        "id": "ZGjdDS4mnrfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"your_token\") # <-- CHANGE THIS to your HuggingFace Login Access Token"
      ],
      "metadata": {
        "id": "aL3dfKiwnn1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: Check GPU and RAM availability"
      ],
      "metadata": {
        "id": "nnI0zS4cnpqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Optional: Check GPU and RAM availability --\n",
        "def print_gpu_ram_info():\n",
        "    try:\n",
        "        import subprocess\n",
        "        # Check GPU info\n",
        "        gpu_info = subprocess.check_output(['nvidia-smi']).decode()\n",
        "        print(\"GPU Info:\\n\", gpu_info)\n",
        "    except Exception:\n",
        "        print('No GPU found or not connected to a GPU.')\n",
        "\n",
        "    # Check RAM info\n",
        "    try:\n",
        "        from psutil import virtual_memory\n",
        "        ram_gb = virtual_memory().total / 1e9\n",
        "        print('Your runtime has {:.1f} GB of available RAM\\n'.format(ram_gb))\n",
        "    except ImportError:\n",
        "        print('psutil not installed, skipping RAM check.')\n",
        "\n",
        "# Call the function (optional)\n",
        "print_gpu_ram_info()"
      ],
      "metadata": {
        "id": "CxbXMDs4wHtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Configuration"
      ],
      "metadata": {
        "id": "LHGIFtBln-8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- User Configuration ---\n",
        "# Provide the name of your model (must be compatible with HuggingFace Transformers)\n",
        "MODEL_NAME = \"your_model\"  # <-- CHANGE THIS to your model\n",
        "\n",
        "# Provide the name of your tokenizer\n",
        "TOKENIZER = \"your_tokenizer\" # <-- CHANGE THIS if not the same as your MODEL_NAME\n",
        "\n",
        "# Path to your test CSV file (should have at least 'EssayText' and 'essay_score' columns)\n",
        "TEST_CSV_PATH = \"path/to/your/test_data.csv\"  # <-- CHANGE THIS to your test data path\n",
        "\n",
        "# Number of classes in your classification problem\n",
        "NUM_LABELS = 2  # <-- CHANGE THIS to your number of classes\n",
        "\n",
        "# Class names (must match your dataset)\n",
        "CLASS_NAMES = [str(i) for i in range(NUM_LABELS)]  # or use your actual class names\n",
        "\n",
        "# Random seed for reproducibility\n",
        "RANDOM_STATE = 0\n",
        "\n",
        "# Folder to save HEDGE attribution score computations\n",
        "DIR = \"path/to/your/folder\" # <-- CHANGE THIS to your folder"
      ],
      "metadata": {
        "id": "roRMvv2bn8Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model and Tokenizer"
      ],
      "metadata": {
        "id": "FgR_sNBeoC-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Model and Tokenizer ---\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)\n",
        "\n",
        "# Use GPU if available, else CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ue9-rmI5oE40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "8ORD5Xm-oGWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Data ---\n",
        "# If using HuggingFace datasets:\n",
        "# test_set = load_dataset('csv', data_files=TEST_CSV_PATH)['train']\n",
        "# test_doc = list(test_set['EssayText'])\n",
        "\n",
        "# Or load with pandas:\n",
        "test = pd.read_csv(TEST_CSV_PATH)\n",
        "assert 'EssayText' in test.columns, \"Your CSV file must have an 'EssayText' column.\"\n",
        "test_doc = list(test['EssayText'])\n",
        "test.head()"
      ],
      "metadata": {
        "id": "RDLwMxpvoGxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Functions to Compute HEDGE Attribution Scores"
      ],
      "metadata": {
        "id": "00mgkgLToNJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADQLIhbgORIe"
      },
      "outputs": [],
      "source": [
        "class HEDGE:\n",
        "    def __init__(self, model, inputs,  device, max_level=-1, thre=0.3):\n",
        "        # Ensure inputs and model are on GPU\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        score = model(**inputs)[1].detach()  # Keep on GPU\n",
        "        score_norm = torch.softmax(score, dim=1).detach()\n",
        "\n",
        "        self.pred_label = torch.argmax(score_norm, dim=1).item()\n",
        "        self.max_level = max_level\n",
        "        self.output = []\n",
        "        self.fea_num = len(inputs['input_ids'][0]) - 2\n",
        "        self.level = 0\n",
        "        #self.args = args\n",
        "        self.thre = thre\n",
        "\n",
        "        # Initial masking for bias calculation\n",
        "        input_ids = inputs['input_ids'][0]\n",
        "        mask_input = torch.zeros(input_ids.shape, dtype=torch.long, device=device)\n",
        "        mask_attention = torch.zeros(input_ids.shape, dtype=torch.long, device=device)\n",
        "        mask_type = torch.zeros(input_ids.shape, dtype=torch.long, device=device)\n",
        "\n",
        "        temp = {\n",
        "            'input_ids': torch.unsqueeze(mask_input, 0),\n",
        "            'attention_mask': torch.unsqueeze(mask_attention, 0),\n",
        "            'token_type_ids': torch.unsqueeze(mask_type, 0),\n",
        "            'labels': inputs['labels']\n",
        "        }\n",
        "\n",
        "        #score = model(**temp)[1].detach()  # Keep on GPU\n",
        "        #score_norm = torch.softmax(score, dim=1).detach()\n",
        "\n",
        "        self.bias = score_norm[0][self.pred_label].item()\n",
        "\n",
        "    def set_contribution_func(self, model, fea_set, inputs):\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}  # Ensure inputs are on GPU\n",
        "        input_ids = inputs['input_ids'][0]\n",
        "\n",
        "        mask_input = torch.zeros(input_ids.shape, dtype=torch.long, device=device)\n",
        "        mask_input[0] = input_ids[0]\n",
        "        mask_input[-1] = input_ids[-1]\n",
        "\n",
        "        mask_attention = torch.zeros(input_ids.shape, dtype=torch.long, device=device)\n",
        "        mask_attention[0] = 1\n",
        "        mask_attention[-1] = 1\n",
        "\n",
        "        mask_type = torch.zeros(input_ids.shape, dtype=torch.long, device=device)\n",
        "\n",
        "        for fea_idx in fea_set:\n",
        "            if isinstance(fea_idx, int):\n",
        "                mask_input[fea_idx+1] = input_ids[fea_idx+1]\n",
        "                mask_attention[fea_idx+1] = 1\n",
        "            else:\n",
        "                for idx in fea_idx:\n",
        "                    mask_input[idx+1] = input_ids[idx+1]\n",
        "                    mask_attention[idx+1] = 1\n",
        "\n",
        "        temp = {\n",
        "            'input_ids': torch.unsqueeze(mask_input, 0),\n",
        "            'attention_mask': torch.unsqueeze(mask_attention, 0),\n",
        "            'token_type_ids': torch.unsqueeze(mask_type, 0),\n",
        "            'labels': inputs['labels']\n",
        "        }\n",
        "\n",
        "        # Model inference with masked inputs\n",
        "        score = model(**temp)[1].detach()  # Keep on GPU\n",
        "        score_norm = torch.softmax(score, dim=1).detach()\n",
        "\n",
        "        return score_norm[0][self.pred_label].item() - self.bias\n",
        "\n",
        "    def shapley_interaction_score_approx(self, model, inputs, feature_set, left, right, win_size):\n",
        "        if left + 1 != right:\n",
        "            print(\"Not adjacent interaction\")\n",
        "            return -1\n",
        "\n",
        "        curr_set_lr = list((feature_set[left], feature_set[right]))\n",
        "        curr_set_l = [feature_set[left]] if isinstance(feature_set[left], int) else feature_set[left]\n",
        "        curr_set_r = [feature_set[right]] if isinstance(feature_set[right], int) else feature_set[right]\n",
        "\n",
        "        fea_num = len(feature_set)\n",
        "        if left - win_size > 0:\n",
        "            left_set = feature_set[left - win_size:left]\n",
        "        else:\n",
        "            left_set = feature_set[0:left]\n",
        "\n",
        "        if right + win_size > fea_num - 1:\n",
        "            right_set = feature_set[right + 1:]\n",
        "        else:\n",
        "            right_set = feature_set[right + 1:right + win_size + 1]\n",
        "\n",
        "        adj_set = left_set + right_set\n",
        "        num_adj = len(adj_set)\n",
        "        dict_subset = {r: list(combinations(adj_set, r)) for r in range(num_adj+1)}\n",
        "\n",
        "        score = 0.0\n",
        "        for i in range(num_adj + 1):\n",
        "            weight = self.get_shapley_interaction_weight(fea_num, i)\n",
        "            if i == 0:\n",
        "                score_included = self.set_contribution_func(model, curr_set_lr, inputs)\n",
        "                score_excluded_l = self.set_contribution_func(model, curr_set_r, inputs)\n",
        "                score_excluded_r = self.set_contribution_func(model, curr_set_l, inputs)\n",
        "                score_excluded = self.set_contribution_func(model, [], inputs)\n",
        "                score += (score_included - score_excluded_l - score_excluded_r + score_excluded) * weight\n",
        "            else:\n",
        "                for subsets in dict_subset[i]:\n",
        "                    score_included = self.set_contribution_func(model, list(subsets) + curr_set_lr, inputs)\n",
        "                    score_excluded_l = self.set_contribution_func(model, list(subsets) + curr_set_r, inputs)\n",
        "                    score_excluded_r = self.set_contribution_func(model, list(subsets) + curr_set_l, inputs)\n",
        "                    score_excluded = self.set_contribution_func(model, list(subsets), inputs)\n",
        "                    score += (score_included - score_excluded_l - score_excluded_r + score_excluded) * weight\n",
        "\n",
        "        return score\n",
        "\n",
        "      # Import the standard library math module\n",
        "\n",
        "    def get_shapley_interaction_weight(self, d, s):\n",
        "        return math.factorial(s) * math.factorial(d - s - 2) / math.factorial(d - 1) / 2\n",
        "\n",
        "\n",
        "    def shapley_interaction_score_approx(self, model, input, feature_set,left, right, win_size):\n",
        "        if left + 1 != right:\n",
        "            print(\"Not adjacent interaction\")\n",
        "            return -1\n",
        "        fea_num = len(feature_set)\n",
        "        curr_set_lr = list((feature_set[left], feature_set[right]))\n",
        "        curr_set_l = [feature_set[left]] if type(feature_set[left]) == int else feature_set[left]\n",
        "        curr_set_r = [feature_set[right]] if type(feature_set[right]) == int else feature_set[right]\n",
        "        if left + 1 - win_size > 0:\n",
        "            left_set = feature_set[left - win_size:left]\n",
        "        else:\n",
        "            left_set = feature_set[0:left]\n",
        "        if right + win_size > fea_num - 1:\n",
        "            right_set = feature_set[right + 1:]\n",
        "        else:\n",
        "            right_set = feature_set[right + 1:right + win_size + 1]\n",
        "        adj_set = left_set + right_set\n",
        "        num_adj = len(adj_set)\n",
        "        dict_subset = {r: list(combinations(adj_set, r)) for r in range(num_adj+1)}\n",
        "        score = 0.0\n",
        "        for i in range(num_adj+1):\n",
        "            weight = self.get_shapley_interaction_weight(fea_num, i)\n",
        "            if i == 0:\n",
        "                score_included = self.set_contribution_func(model, curr_set_lr, input)\n",
        "                score_excluded_l = self.set_contribution_func(model, curr_set_r, input)\n",
        "                score_excluded_r = self.set_contribution_func(model, curr_set_l, input)\n",
        "                score_excluded = self.set_contribution_func(model, [], input)\n",
        "                score += (score_included - score_excluded_l - score_excluded_r + score_excluded) * weight\n",
        "            else:\n",
        "                for subsets in dict_subset[i]:\n",
        "                    score_included = self.set_contribution_func(model, list(subsets) + curr_set_lr, input)\n",
        "                    score_excluded_l = self.set_contribution_func(model, list(subsets) + curr_set_r, input)\n",
        "                    score_excluded_r = self.set_contribution_func(model, list(subsets) + curr_set_l, input)\n",
        "                    score_excluded = self.set_contribution_func(model, list(subsets), input)\n",
        "                    score += (score_included - score_excluded_l - score_excluded_r + score_excluded) * weight\n",
        "        return score\n",
        "\n",
        "    def shapley_topdown_tree(self, model, inputs, win_size):\n",
        "        fea_num = self.fea_num\n",
        "        if fea_num == 0:\n",
        "            return -1\n",
        "        fea_set = [list(range(fea_num))]\n",
        "        if self.max_level < 1:\n",
        "            self.max_level = 300\n",
        "        #begin split the sentence\n",
        "        pos = 0\n",
        "        level = 0\n",
        "        hier_tree = {}\n",
        "        hier_tree[0] = fea_set\n",
        "        for level in range(1, self.fea_num):\n",
        "            pos = 0\n",
        "            min_inter_score = 1e8\n",
        "            pos_opt = 0\n",
        "            inter_idx_opt = 0\n",
        "            while pos < len(fea_set):\n",
        "                subset = fea_set[pos]\n",
        "                sen_len = len(subset)\n",
        "                if sen_len == 1:\n",
        "                    pos += 1\n",
        "                    continue\n",
        "                new_fea_set = [ele for x, ele in enumerate(fea_set) if x != pos]\n",
        "                score_buff = []\n",
        "                for idx in range(1, sen_len):\n",
        "                    leave_one_set = deepcopy(new_fea_set)\n",
        "                    sub_set1 = subset[0:idx]\n",
        "                    sub_set2 = subset[idx:]\n",
        "                    leave_one_set.insert(pos, sub_set1)\n",
        "                    leave_one_set.insert(pos + 1, sub_set2)\n",
        "                    score_buff.append(self.shapley_interaction_score_approx(model, inputs, leave_one_set, pos, pos + 1, win_size))\n",
        "                inter_score = np.array(score_buff)\n",
        "                min_inter_idx = np.argmin(inter_score)\n",
        "                minter = inter_score[min_inter_idx]\n",
        "                if minter < min_inter_score:\n",
        "                    min_inter_score = minter\n",
        "                    inter_idx_opt = min_inter_idx\n",
        "                    pos_opt = pos\n",
        "                pos += 1\n",
        "\n",
        "            new_fea_set = [ele for x, ele in enumerate(fea_set) if x != pos_opt]\n",
        "            subset = fea_set[pos_opt]\n",
        "            sub_set1 = subset[0:inter_idx_opt + 1]\n",
        "            sub_set2 = subset[inter_idx_opt + 1:]\n",
        "            new_fea_set.insert(pos_opt, sub_set1)\n",
        "            new_fea_set.insert(pos_opt + 1, sub_set2)\n",
        "            fea_set = new_fea_set\n",
        "            hier_tree[level] = fea_set\n",
        "        self.max_level = level\n",
        "        self.hier_tree = hier_tree\n",
        "        return hier_tree\n",
        "\n",
        "    def compute_shapley_hier_tree(self, model, inputs, win_size):\n",
        "        hier_tree = self.shapley_topdown_tree(model,inputs, win_size)\n",
        "        self.hier_tree = {}\n",
        "        for level in range(self.max_level+1):\n",
        "            self.hier_tree[level] = []\n",
        "            for subset in hier_tree[level]:\n",
        "                self.hier_tree[level].append((subset,2*(self.set_contribution_func(model,subset, inputs)+self.bias)-1))\n",
        "        return self.hier_tree\n",
        "\n",
        "    def get_importance_phrase(self, num=-1):\n",
        "        hier_list = []\n",
        "\n",
        "        for level in range(1, self.max_level + 1):\n",
        "            for fea_set, score in self.hier_tree[level]:\n",
        "                hier_list.append((fea_set, score))\n",
        "        hier_list = sorted(hier_list, key=lambda item: item[1], reverse=True)\n",
        "        phrase_list = []\n",
        "        if num == -1:\n",
        "            num = 10000\n",
        "        pre_items = []\n",
        "        score_list = []\n",
        "        count = 0\n",
        "        for items, score in hier_list:\n",
        "            if count == num:\n",
        "                break\n",
        "            if not set(items) == set(pre_items):\n",
        "                phrase_list.append(items)\n",
        "                score_list.append(score)\n",
        "                pre_items = items\n",
        "                count += 1\n",
        "        return phrase_list, score_list\n",
        "\n",
        "\n",
        "    def collect_unsplit_items(self):\n",
        "        levels = range(self.max_level)\n",
        "        words_list = []\n",
        "        for level in levels:\n",
        "            for fea in self.hier_tree[level]:\n",
        "                #get next level words\n",
        "                next_level_list = []\n",
        "                for item in self.hier_tree[level+1]:\n",
        "                    next_level_list += item[0]\n",
        "                if len(set(fea[0]).intersection(set(next_level_list)))==0:\n",
        "                    words_list.append((fea[0],fea[1]))\n",
        "        words_list = sorted(words_list, key=lambda item: item[1], reverse=True)\n",
        "        return words_list\n",
        "\n",
        "    def complete_hier_tree(self):\n",
        "        # word_dict = {}\n",
        "        hier_tree = {}\n",
        "        word_list = self.collect_unsplit_items()\n",
        "\n",
        "        for level in range(self.max_level + 1):\n",
        "            hier_tree[level] = []\n",
        "            ele_list = []\n",
        "            for subset in self.hier_tree[level]:\n",
        "                hier_tree[level].append(subset)\n",
        "                ele_list += subset[0]\n",
        "            for ele in word_list:\n",
        "                if len(set(ele_list).intersection(set(ele[0]))) == 0:\n",
        "                    hier_tree[level].append((ele[0], ele[1]))\n",
        "        return hier_tree\n",
        "\n",
        "    def get_last_level_phrases(self, inputs):\n",
        "        text = inputs['input_ids'][0]\n",
        "        text = text.detach().to(device).numpy()\n",
        "        hier_tree = self.complete_hier_tree()\n",
        "        last_level = hier_tree[self.max_level]\n",
        "        ordered_list = sorted(last_level, key=lambda item: item[1], reverse=True)\n",
        "        return [[text[idx+1] for idx in idx_set[0]] for idx_set in ordered_list]\n",
        "\n",
        "\n",
        "    def visualize_tree(self, batch, tokenizer, fontsize=10, tag=''):\n",
        "        text = batch['input_ids'][0]\n",
        "        text = text.detach().to(device).numpy()\n",
        "        levels = self.max_level\n",
        "        vals = np.array([fea[1] for level in range(levels) for fea in self.hier_tree[level]])\n",
        "        min_val = np.min(vals)\n",
        "        max_val = np.max(vals)\n",
        "        import matplotlib as mpl\n",
        "        import matplotlib.pyplot as plt\n",
        "        cnorm = mpl.colors.Normalize(vmin=-1, vmax=1, clip=False)\n",
        "        if self.pred_label == 1:  # 1 stands for positive\n",
        "            cmapper = mpl.cm.ScalarMappable(norm=cnorm, cmap='RdYlBu')\n",
        "        else:  # 0 stands for negative\n",
        "            cmapper = mpl.cm.ScalarMappable(norm=cnorm, cmap='RdYlBu_r')\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 7))\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ylabels = ['Level ' + str(idx) for idx in range(self.max_level + 1)]\n",
        "        ax.set_yticks(list(range(0, self.max_level + 1)))\n",
        "        ax.set_yticklabels(ylabels)\n",
        "        ax.set_ylim(self.max_level + 0.5, 0 - 0.5)\n",
        "        sep_len = 0.3\n",
        "        for key in range(levels+1):\n",
        "            for fea in self.hier_tree[key]:\n",
        "                len_fea = len(fea[0])\n",
        "                start_fea = fea[0] if type(fea[0])==int else fea[0][0]\n",
        "                start = sep_len * start_fea + start_fea + 0.5\n",
        "                width = len_fea + sep_len * (len_fea - 1)\n",
        "                fea_color = cmapper.to_rgba(fea[1])\n",
        "                r, g, b, _ = fea_color\n",
        "                c = ax.barh(key, width=width, height=0.5, left=start, color=fea_color)\n",
        "                text_color = 'white' if r * g * b < 0.3 else 'black'\n",
        "                #         text_color = 'black'\n",
        "                word_idxs = fea[0]\n",
        "                for i, idx in enumerate(word_idxs):\n",
        "                    word_pos = start + sep_len * (i) + i + 0.5\n",
        "                    word_str = tokenizer.ids_to_tokens[text[idx+1]]#+1 accounts for the CLS token at the begining\n",
        "                    ax.text(word_pos, key, word_str, ha='center', va='center',\n",
        "                            color=text_color, fontsize=fontsize)\n",
        "                    word_pos += sep_len\n",
        "                start += (width + sep_len)\n",
        "        fig.colorbar(cmapper, ax=ax)\n",
        "        plt.savefig('visualization_sentence_{}.png'.format(tag))\n",
        "#        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Functions to Compute AOPC"
      ],
      "metadata": {
        "id": "w3UBoGB0pfOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_aopc_top_20_percent(hedge, model, inputs, word_list, score_list, tokenizer, device):\n",
        "    # Ensure each tensor in the inputs dictionary is moved to the correct device\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    # Step 1: Get the model's original prediction confidence\n",
        "    with torch.no_grad():\n",
        "        original_output = model(**inputs)  # Ensure inputs are on GPU\n",
        "        logits = original_output.logits  # Access logits from the output\n",
        "        score = logits  # Keep the logits on the GPU\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        score_norm = torch.softmax(score, dim=1)\n",
        "        original_confidence = score_norm[0][hedge.pred_label]\n",
        "\n",
        "    # Step 2: Identify the top 20% most important tokens\n",
        "    important_phrases = [i for i, j in zip(word_list, score_list) if len(i)==1]\n",
        "    score_list = [j for i, j in zip(word_list, score_list) if len(i)==1]\n",
        "\n",
        "    num_tokens = sum([len(phrase) for phrase in important_phrases])\n",
        "    top_20_percent_count = max(1, int(0.2 * num_tokens))  # Ensure at least 1 token is masked\n",
        "\n",
        "    # Flatten important_phrases and score_list to a single list of (token_indices, score)\n",
        "    flat_phrases_scores = [(token_set, score) for token_set, score in zip(important_phrases, score_list)]\n",
        "    flat_phrases_scores = sorted(flat_phrases_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Collect the top 20% token indices\n",
        "    top_tokens = []\n",
        "    count = 0\n",
        "    for phrase, score in flat_phrases_scores:\n",
        "        top_tokens.extend(phrase)\n",
        "        count += len(phrase)\n",
        "        if count >= top_20_percent_count:\n",
        "            break\n",
        "\n",
        "    total_score_drop = 0\n",
        "    top_tokens_scores = [ (tokens[i[0]+1], round(j,3), i ) for i , j in flat_phrases_scores]\n",
        "\n",
        "    for i in range(1, len(top_tokens) + 1):\n",
        "        # Perturb the input by removing the top i important tokens\n",
        "        # Step 3: Remove the top 20% important tokens by replacing them with the PAD token\n",
        "\n",
        "        indices_to_remove = top_tokens[:i]\n",
        "        perturbed_tokens = [tokens[j] for j in range(len(tokens)) if j not in indices_to_remove]\n",
        "        perturbed_input = tokenizer(\" \".join(perturbed_tokens), return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "        perturbed_input = {\n",
        "            'input_ids': perturbed_input['input_ids'],\n",
        "            'attention_mask': perturbed_input['attention_mask'],\n",
        "            'token_type_ids': perturbed_input.get('token_type_ids'),  # Not all tokenizers return token_type_ids\n",
        "            'labels': inputs['labels'].to(device)\n",
        "        }\n",
        "\n",
        "        # Step 4: Get the model's new confidence after masking the top 20% important tokens\n",
        "        with torch.no_grad():\n",
        "            masked_output = model(**perturbed_input)\n",
        "            masked_logits = masked_output.logits  # Access logits from the output\n",
        "            masked_score = masked_logits  # Keep the logits on the GPU\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            masked_score_norm = torch.softmax(masked_score, dim=1)\n",
        "            masked_confidence = masked_score_norm[0][hedge.pred_label]\n",
        "\n",
        "        # Step 5: Calculate AOPC (original - new confidence for top 20% masked)\n",
        "        score_drop = original_confidence - masked_confidence\n",
        "        print(score_drop)\n",
        "        total_score_drop += score_drop.item()\n",
        "\n",
        "    aopc = total_score_drop / len(top_tokens)\n",
        "    return aopc, top_tokens_scores"
      ],
      "metadata": {
        "id": "WlFdDjiEOTcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Loop: Calculate AOPC for Test Set"
      ],
      "metadata": {
        "id": "0n5Cp_7NpqlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "dir_ = DIR\n",
        "\n",
        "#final_hedge = []\n",
        "#final_list = []\n",
        "for ex, sc in zip(test['EssayText'].values, test['essay_score'].values):\n",
        "  inputs = tokenizer(ex, return_tensors='pt')\n",
        "  inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "  inputs['labels'] = torch.tensor([int(sc)]).to(device)\n",
        "\n",
        "  hedge = HEDGE(model, inputs, device)\n",
        "  print(ex)\n",
        "  print('processing ---------------------', i)\n",
        "  hedge.compute_shapley_hier_tree(model, inputs, 2)\n",
        "  word_list, score_list = hedge.get_importance_phrase()\n",
        "  tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "\n",
        "  aopc_hedge, attribution_score_list  = compute_aopc_top_20_percent(hedge, model, inputs, word_list, score_list, tokenizer, device)\n",
        "\n",
        "  print(f\"HEDGE attribution scores: {attribution_score_list}\")\n",
        "  print(f\"AOPC using HEDGE scores: {aopc_hedge}\")\n",
        "  #final_hedge.append(aopc_hedge)\n",
        "  #final_list.append(attribution_score_list)\n",
        "\n",
        "  with open(dir_+str(i)+'.txt', 'w') as t:\n",
        "    t.write(str(aopc_hedge))\n",
        "    t.write('\\n')\n",
        "    t.write(str(attribution_score_list))\n",
        "    t.close()\n",
        "    print(i)\n",
        "  i+=1\n",
        "\n",
        "#print(np.mean(final_hedge))"
      ],
      "metadata": {
        "id": "jvNOUIzJOUls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}